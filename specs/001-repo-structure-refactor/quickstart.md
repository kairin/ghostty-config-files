# Quickstart: Repository Structure Refactoring

**Feature**: 001-repo-structure-refactor
**Target Audience**: Developers implementing this feature
**Estimated Time**: 2-3 development sessions (8-12 hours total)

## Overview

This guide walks through implementing the repository structure refactoring feature, which consolidates management operations into `manage.sh`, separates documentation source from generated content, and modularizes the monolithic `start.sh` script.

---

## Prerequisites

### System Requirements

- Ubuntu 25.04+ (or compatible Linux distribution)
- Bash 5.x+
- Node.js LTS (for Astro documentation builds)
- Git 2.30+
- ShellCheck (for script validation)

### Knowledge Requirements

- Bash scripting (functions, sourcing, error handling)
- Git workflow (branches, commits, merges)
- Basic understanding of Astro.build (for documentation)
- Familiarity with testing bash scripts

### Setup

```bash
# Clone repository
cd /home/kkk/Apps/ghostty-config-files

# Checkout feature branch
git checkout 001-repo-structure-refactor

# Verify local CI/CD works
./local-infra/runners/gh-workflow-local.sh status

# Read planning documents
cat specs/001-repo-structure-refactor/plan.md
cat specs/001-repo-structure-refactor/research.md
cat specs/001-repo-structure-refactor/data-model.md
```

---

## Implementation Phases

### Phase 0: Planning & Research ‚úÖ COMPLETE

**Status**: Completed by `/speckit.plan` command

**Artifacts**:
- `plan.md` - Implementation plan with technical context
- `research.md` - Research on bash testing, .nojekyll preservation, module architecture
- `data-model.md` - Entity definitions (Bash Module, Documentation Artifact, etc.)
- `contracts/` - CLI and module interface contracts

**Key Decisions**:
1. **Testing**: Hybrid approach (ShellCheck + Custom Functions + Pytest)
2. **.nojekyll**: Multi-layered defense (Astro public/ + Vite plugin + git hooks)
3. **Architecture**: Flat scripts/ directory with function-based modules

---

### Phase 1: Design & Contracts ‚úÖ COMPLETE

**Status**: Completed by `/speckit.plan` command

**Artifacts**:
- `data-model.md` - Complete entity definitions with validation rules
- `contracts/manage-sh-cli.md` - CLI interface contract for manage.sh
- `contracts/bash-module-interface.md` - Function interface contract for modules
- `quickstart.md` - This file

**Next Step**: Generate tasks with `/speckit.tasks` command

---

### Phase 2: Task Generation (Next Step)

**Command**: `/speckit.tasks`

**What It Does**:
- Parses `plan.md`, `research.md`, `data-model.md`, and `contracts/`
- Generates actionable, dependency-ordered tasks in `tasks.md`
- Each task includes acceptance criteria and time estimates

**Expected Output**:
```
specs/001-repo-structure-refactor/tasks.md
```

**Example Tasks** (will be generated):
1. Create module template and validation script
2. Implement first bash module (e.g., `install_node.sh`)
3. Write unit tests for first module
4. Create `manage.sh` orchestrator skeleton
5. ... (full task list generated by /speckit.tasks)

---

### Phase 3: Implementation (After Task Generation)

**Command**: `/speckit.implement` or manual implementation

**Process**:
1. Review generated `tasks.md`
2. Execute tasks in dependency order
3. Run local CI/CD validation after each task
4. Commit incrementally with descriptive messages

---

## Quick Start Commands

### For Planning Phase (Current)

```bash
# View implementation plan
cat specs/001-repo-structure-refactor/plan.md

# Read research findings
cat specs/001-repo-structure-refactor/research.md

# Review data model
cat specs/001-repo-structure-refactor/data-model.md

# Review contracts
cat specs/001-repo-structure-refactor/contracts/*.md

# Generate tasks (next step)
claude /speckit.tasks
```

### For Implementation Phase (After Task Generation)

```bash
# View generated tasks
cat specs/001-repo-structure-refactor/tasks.md

# Create first module from template
cp scripts/.module-template.sh scripts/install_node.sh

# Validate module contract compliance
./scripts/validate_module_contract.sh scripts/install_node.sh

# Run ShellCheck
shellcheck -x scripts/install_node.sh

# Write and run unit tests
./local-infra/tests/unit/test_install_node.sh

# Validate all changes
./local-infra/runners/gh-workflow-local.sh all

# Commit incrementally
DATETIME=$(date +"%Y%m%d-%H%M%S")
git add scripts/install_node.sh local-infra/tests/unit/test_install_node.sh
git commit -m "feat: Add install_node.sh module with unit tests

Implements FR-008: Modular script for Node.js installation.
Module follows bash-module-interface contract.
Unit tests pass in 4.2 seconds (under 10s requirement).

ü§ñ Generated with [Claude Code](https://claude.ai/code)
Co-Authored-By: Claude <noreply@anthropic.com>"
```

### For Testing & Validation

```bash
# Run specific module unit tests
./local-infra/tests/unit/test_install_node.sh

# Run all unit tests
./local-infra/runners/test-runner-local.sh --type unit

# Run integration tests
./local-infra/runners/test-runner-local.sh --type integration

# Run complete local CI/CD
./local-infra/runners/gh-workflow-local.sh all

# Validate manage.sh CLI contract
pytest local-infra/tests/contract/test_manage_cli.py

# Check for circular dependencies
./scripts/validate_module_deps.sh
```

---

## Development Workflow

### Incremental Implementation

This feature uses **incremental per-component migration** (from spec.md clarifications):

1. **Migrate one module at a time**: Start with simple modules (e.g., `validate_config.sh`)
2. **Test independently**: Each module must pass unit tests before integration
3. **Integrate gradually**: Add to `manage.sh` one command at a time
4. **Maintain compatibility**: Existing `start.sh` continues working throughout

### Recommended Order

Based on dependency analysis:

```
1. Common utilities (scripts/common.sh, scripts/progress.sh)
2. Validation modules (scripts/validate_config.sh, scripts/dependency_check.sh)
3. Installation modules (scripts/install_node.sh, scripts/install_zig.sh)
4. Build modules (scripts/build_ghostty.sh)
5. Configuration modules (scripts/setup_zsh.sh, scripts/configure_theme.sh)
6. Integration modules (scripts/install_context_menu.sh)
7. Orchestrator (manage.sh)
8. Documentation restructure (docs-source/, docs-dist/)
9. Wrapper update (start.sh becomes wrapper)
```

### Daily Development Cycle

```bash
# Morning: Sync with main
git fetch origin
git merge origin/main --no-ff

# Select next task
cat specs/001-repo-structure-refactor/tasks.md
# Mark task as "in progress"

# Implement task
# Write code, write tests, validate

# Afternoon: Local CI/CD
./local-infra/runners/gh-workflow-local.sh all

# If tests pass: Commit
DATETIME=$(date +"%Y%m%d-%H%M%S")
git add <changed-files>
git commit -m "<descriptive message>"

# Evening: Merge to main (if milestone complete)
git checkout main
git merge 001-repo-structure-refactor --no-ff
git push origin main

# Never delete feature branch (constitutional requirement)
git checkout 001-repo-structure-refactor
```

---

## Testing Strategy

### Unit Tests (Per Module)

**Location**: `local-infra/tests/unit/test_<module>.sh`

**Requirements**:
- Test all public functions
- Mock external dependencies
- Complete in <10 seconds
- Use subshells for isolation

**Example**:
```bash
#!/bin/bash
# local-infra/tests/unit/test_install_node.sh

set -euo pipefail

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(cd "$SCRIPT_DIR/../.." && pwd)"

# Source module under test
source "$PROJECT_ROOT/scripts/install_node.sh"

# Test: validate_node_installation detects missing node
test_validate_node_missing() {
    export PATH="/usr/bin:/bin"  # Remove node from PATH

    if validate_node_installation; then
        echo "‚ùå FAIL: Should return false when node missing"
        return 1
    else
        echo "‚úÖ PASS: Correctly detects missing node"
        return 0
    fi
}

# Test: validate_node_installation detects present node
test_validate_node_present() {
    # Create mock node
    local mock_dir="/tmp/mock_node_$$"
    mkdir -p "$mock_dir"
    echo '#!/bin/bash\necho "v20.0.0"' > "$mock_dir/node"
    echo '#!/bin/bash\necho "10.0.0"' > "$mock_dir/npm"
    chmod +x "$mock_dir/node" "$mock_dir/npm"

    export PATH="$mock_dir:$PATH"

    if validate_node_installation; then
        echo "‚úÖ PASS: Correctly detects present node"
        rm -rf "$mock_dir"
        return 0
    else
        echo "‚ùå FAIL: Should return true when node present"
        rm -rf "$mock_dir"
        return 1
    fi
}

# Run tests
test_validate_node_missing
test_validate_node_present
```

### Integration Tests (End-to-End)

**Location**: `local-infra/tests/contract/test_manage_cli.py`

**Requirements**:
- Test complete workflows (e.g., `manage.sh install`)
- Validate CLI contract compliance
- Use pytest framework (existing infrastructure)

**Example**:
```python
import subprocess
import pytest

def test_manage_install_help():
    """Verify manage.sh install --help displays usage"""
    result = subprocess.run(
        ["./manage.sh", "install", "--help"],
        capture_output=True,
        text=True
    )
    assert result.returncode == 0
    assert "Usage:" in result.stdout
    assert "install" in result.stdout

def test_manage_install_dry_run():
    """Verify manage.sh install --dry-run doesn't modify system"""
    # Record pre-state
    pre_state = capture_system_state()

    # Run dry-run
    result = subprocess.run(
        ["./manage.sh", "install", "--dry-run"],
        capture_output=True,
        text=True
    )

    # Verify no changes
    post_state = capture_system_state()
    assert pre_state == post_state
    assert result.returncode == 0
```

### Validation Tests

**Location**: `local-infra/tests/validation/`

**Requirements**:
- ShellCheck: All modules pass with zero errors
- Syntax: `bash -n` validation
- Dependencies: No circular references
- Performance: Unit tests complete in <10s

**Run All Validations**:
```bash
./local-infra/runners/validate-modules.sh
```

---

## Common Tasks

### Create New Bash Module

```bash
# Copy template
cp scripts/.module-template.sh scripts/new_module.sh

# Edit module
vim scripts/new_module.sh
# - Update header (Purpose, Dependencies, Exit Codes)
# - Implement public functions
# - Add function documentation

# Validate contract compliance
./scripts/validate_module_contract.sh scripts/new_module.sh

# Run ShellCheck
shellcheck -x scripts/new_module.sh

# Create unit test
cp local-infra/tests/unit/.test-template.sh \
   local-infra/tests/unit/test_new_module.sh

# Edit test
vim local-infra/tests/unit/test_new_module.sh

# Run test
./local-infra/tests/unit/test_new_module.sh

# Verify <10s execution time
time ./local-infra/tests/unit/test_new_module.sh
```

### Add Command to manage.sh

```bash
# Edit manage.sh
vim manage.sh

# Add case statement
case "${1:-}" in
    "install") ... ;;
    "docs") ... ;;
    "new-command")  # Add new command
        source "$SCRIPTS_DIR/new_module.sh"
        new_module_function "$@" || exit 1
        ;;
    *)
        show_help
        exit 1
        ;;
esac

# Test command
./manage.sh new-command --help

# Add integration test
vim local-infra/tests/contract/test_manage_cli.py

def test_manage_new_command_help():
    result = subprocess.run(["./manage.sh", "new-command", "--help"])
    assert result.returncode == 0

# Run integration tests
pytest local-infra/tests/contract/test_manage_cli.py
```

### Update Documentation Structure

```bash
# Create docs-source structure
mkdir -p docs-source/{user-guide,ai-guidelines,developer}

# Move existing docs to docs-source
git mv docs/existing-doc.md docs-source/user-guide/

# Configure Astro to use docs-source
vim astro.config.mjs
# Update content paths

# Build to docs-dist
npm run build

# Verify .nojekyll exists
ls -la docs-dist/.nojekyll

# Test locally
npx astro preview

# Validate GitHub Pages compatibility
./local-infra/runners/gh-pages-setup.sh
```

---

## Troubleshooting

### Issue: Module fails ShellCheck

**Symptom**: `shellcheck scripts/module.sh` shows errors

**Solution**:
```bash
# Run with explanations
shellcheck -x -f gcc scripts/module.sh

# Common issues:
# - SC2086: Quote variable expansions
# - SC2034: Unused variable (remove or use)
# - SC1090: Can't follow source (use absolute path)

# Fix and re-validate
vim scripts/module.sh
shellcheck -x scripts/module.sh
```

### Issue: Unit test takes >10 seconds

**Symptom**: `time ./test_module.sh` exceeds 10 seconds

**Solution**:
```bash
# Profile test execution
bash -x ./local-infra/tests/unit/test_module.sh 2>&1 | tee /tmp/test-trace.log

# Common causes:
# - Not mocking external commands (real network calls, slow binaries)
# - Not using subshells (tests interfere with each other)
# - Too many test cases (split into multiple test files)

# Fix:
# - Mock all external dependencies
# - Use PATH override for command mocking
# - Split test file if >15 test cases
```

### Issue: Circular dependency detected

**Symptom**: `./scripts/validate_module_deps.sh` reports cycle

**Solution**:
```bash
# View dependency graph
./scripts/validate_module_deps.sh --graph

# Identify cycle
# Example: A requires B, B requires C, C requires A

# Fix: Extract common functionality
# Create scripts/common_utils.sh with shared functions
# Have A, B, C all source common_utils.sh (no cycle)

# Re-validate
./scripts/validate_module_deps.sh
```

### Issue: manage.sh command fails integration test

**Symptom**: `pytest test_manage_cli.py::test_install` fails

**Solution**:
```bash
# Run with verbose output
pytest -vv -s test_manage_cli.py::test_install

# Check logs
cat /tmp/manage-test-*.log

# Common causes:
# - Module returns wrong exit code
# - Missing --dry-run support
# - Error message not going to stderr

# Debug:
./manage.sh install --dry-run --verbose

# Fix module and re-test
```

---

## Performance Targets

### Per-Module Targets

| Metric | Target | Validation |
|--------|--------|------------|
| Unit test execution | <10s | `time ./test_module.sh` |
| ShellCheck validation | <1s | `time shellcheck module.sh` |
| Function execution | <60s | Add timing logs |
| Module file size | <500 lines | `wc -l module.sh` |

### Overall Targets

| Metric | Target | Validation |
|--------|--------|------------|
| Total unit tests | <90s | `time test-runner-local.sh --type unit` |
| Integration tests | <120s | `time pytest test_manage_cli.py` |
| Full CI/CD pipeline | <600s | `time gh-workflow-local.sh all` |
| manage.sh help | <2s | `time ./manage.sh --help` |

---

## Success Criteria Checklist

### From spec.md Success Criteria

- [ ] **SC-001**: `./manage.sh <command>` works without referencing other scripts
- [ ] **SC-002**: New contributors find docs on first attempt without confusion
- [ ] **SC-003**: Generated artifacts never appear in `git status` after builds
- [ ] **SC-004**: Time to locate functionality reduces by 50%
- [ ] **SC-005**: `manage.sh --help` displays in <2 seconds
- [ ] **SC-006**: All existing automation continues working
- [ ] **SC-007**: Each module tests independently in <10 seconds
- [ ] **SC-008**: Repository size constant or decreases
- [ ] **SC-009**: Zero data loss during migration (backups created)
- [ ] **SC-010**: Documentation builds complete in same or better time
- [ ] **SC-011**: Astro site provides clear navigation (<2 clicks)
- [ ] **SC-012**: Each increment completes in single development session

### Constitutional Compliance

- [ ] Branch preserved (never deleted)
- [ ] Local CI/CD validates all changes before GitHub
- [ ] Zero GitHub Actions consumption
- [ ] .nojekyll preserved in docs-dist/
- [ ] spec-kit/, local-infra/, .specify/ unchanged
- [ ] Conversation log saved at end

---

## Resources

### Documentation

- **Specification**: `specs/001-repo-structure-refactor/spec.md`
- **Implementation Plan**: `specs/001-repo-structure-refactor/plan.md`
- **Research Findings**: `specs/001-repo-structure-refactor/research.md`
- **Data Model**: `specs/001-repo-structure-refactor/data-model.md`
- **Contracts**: `specs/001-repo-structure-refactor/contracts/*.md`

### Tools

- **ShellCheck**: `https://www.shellcheck.net/`
- **Google Bash Style Guide**: `https://google.github.io/styleguide/shellguide.html`
- **Astro Documentation**: `https://docs.astro.build/`
- **Pytest Documentation**: `https://docs.pytest.org/`

### Templates

- **Module Template**: `scripts/.module-template.sh` (to be created)
- **Test Template**: `local-infra/tests/unit/.test-template.sh` (to be created)

### Support

- **GitHub Issues**: `https://github.com/kairin/ghostty-config-files/issues`
- **CLAUDE.md**: Project constitution and requirements
- **Local CI/CD Logs**: `/tmp/ghostty-start-logs/`, `./local-infra/logs/`

---

## Next Steps

1. **Generate Tasks**: Run `/speckit.tasks` to create actionable task list
2. **Review Tasks**: Read generated `tasks.md` and understand dependencies
3. **Start Implementation**: Begin with first task (likely module template creation)
4. **Iterate**: Implement ‚Üí Test ‚Üí Validate ‚Üí Commit ‚Üí Repeat
5. **Deploy**: After all tasks complete, merge to main and deploy

---

## Estimated Timeline

| Phase | Duration | Effort |
|-------|----------|--------|
| Task Generation | 10 minutes | `/speckit.tasks` command |
| Module Template + Validation | 1-2 hours | Create reusable template |
| First Module (install_node.sh) | 2-3 hours | Implementation + tests |
| Additional Modules (10-12 more) | 8-10 hours | Parallel development possible |
| manage.sh Orchestrator | 2-3 hours | CLI routing + integration |
| Documentation Restructure | 2-3 hours | docs-source/ + Astro config |
| Testing & Validation | 2-3 hours | Full CI/CD validation |
| **Total** | **20-25 hours** | **2-3 development sessions** |

---

**Status**: Phase 1 complete. Ready for task generation with `/speckit.tasks`.

**Last Updated**: 2025-10-27
